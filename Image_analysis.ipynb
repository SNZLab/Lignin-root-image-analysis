{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arabidopsis seedlings are incubated with certain pharmaceuticals that attack the cell wall of the plants. This leads to increased production of lignin, a polymer that causes the seedlings to \"stiffen\" so that nothing can get through the cell wall anymore. For analysis, we use a specific dye that docks onto the individual lignin polymers, making them visible. And this is exactly where our interest lies. Using Fiji or ImageJ, we have to manually quantify the stained regions for every sample we analyse, sometimes several hundreds in number. Instead, we would like to have a tool that can be fed with all the images and quantifies the stained regions within seconds.\n",
    "\n",
    "<img src=\"images/root0001.tif\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/root_images\\root0001.tif\n",
      "images/root_images\\root0002.tif\n",
      "images/root_images\\root0003.tif\n",
      "images/root_images\\root0004.tif\n",
      "images/root_images\\root0005.tif\n",
      "images/root_images\\root0006.tif\n",
      "images/root_images\\root0007.tif\n",
      "images/root_images\\root0008.tif\n",
      "images/root_images\\root0009.tif\n",
      "images/root_images\\root0010.tif\n"
     ]
    }
   ],
   "source": [
    "# assign directory\n",
    "directory = 'images/root_images'\n",
    " \n",
    "# iterate over files in directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Grayscale Image' at 0x29fc80351b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read image\n",
    "img = cv.imread(\"images/root_images/root0004.tif\")\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Visualize images using napari (will open in a separate window)\n",
    "# Create an empty viewer\n",
    "viewer = napari.Viewer()\n",
    "# Add images as layers\n",
    "viewer.add_image(img, rgb=True, name='Original Image')\n",
    "viewer.add_image(img_gray, name='Grayscale Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x, y] = img_gray.shape\n",
    "max_row = np.zeros(x)\n",
    "min_row = np.zeros(x)\n",
    "boolean = np.full(x, False)\n",
    "\n",
    "for i in range(x):\n",
    "    max_row[i] = np.max(img_gray[i,:])\n",
    "    min_row[i] = np.min(img_gray[i,:])\n",
    "    boolean[i] = max_row[i]-min_row[i]>=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_cp = boolean.copy()\n",
    "\n",
    "boolean_cp[:99] = False\n",
    "boolean_cp[-99:] = False\n",
    "\n",
    "for i in range(100,x-100):\n",
    "    if not(boolean_cp[i] == True and sum(boolean_cp[i-10:i+10])>=10):\n",
    "        boolean_cp[i] = False\n",
    "\n",
    "idx_upper = np.where(boolean_cp == True)[0][0] - 50\n",
    "idx_lower = np.where(boolean_cp == True)[0][-1] + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Cropped Image' at 0x29fc881ba60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crop region of interest\n",
    "img_gray_cp = img_gray.copy()\n",
    "# img_gray_cp[:idx_upper,:] = 255\n",
    "# img_gray_cp[idx_lower:,:] = 255\n",
    "\n",
    "img_gray_cp[:225] = 255\n",
    "img_gray_cp[-225:] = 255\n",
    "\n",
    "viewer.add_image(img_gray_cp, name='Cropped Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global thresholding\n",
    "_, thresh1 = cv.threshold(img_gray_cp,100,255,cv.THRESH_BINARY)\n",
    "_, thresh2 = cv.threshold(img_gray_cp,125,255,cv.THRESH_BINARY)\n",
    "_, thresh3 = cv.threshold(img_gray_cp,150,255,cv.THRESH_BINARY)\n",
    "\n",
    "titles = ['Global Thresh @100','Global Thresh @125','Global Thresh @150']\n",
    "images = [thresh1, thresh2, thresh3]\n",
    "\n",
    "for i in range(len(images)):\n",
    "    viewer.add_image(images[i], name=titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 202 169.93820121593046\n",
      "108.0 147.0 176.0\n",
      "94.60598321780373 131.47368790838192 159.88508091935265\n"
     ]
    }
   ],
   "source": [
    "min = np.min(img_gray_cp[idx_upper+1:idx_lower-1,:])\n",
    "max = np.max(img_gray_cp[idx_upper+1:idx_lower-1,:])\n",
    "avg = np.average(img_gray_cp[idx_upper+1:idx_lower-1,:])\n",
    "print(min, max, avg)\n",
    "\n",
    "q_50 = np.quantile(img_gray_cp[idx_upper+1:idx_lower-1,:],0.50)\n",
    "q_10 = np.quantile(img_gray_cp[idx_upper+1:idx_lower-1,:],0.10)\n",
    "q_01 = np.quantile(img_gray_cp[idx_upper+1:idx_lower-1,:],0.01)\n",
    "print(q_01, q_10, q_50)\n",
    "\n",
    "print(np.average(img_gray_cp[img_gray_cp <= q_01]),np.average(img_gray_cp[img_gray_cp <= q_10]),np.average(img_gray_cp[img_gray_cp <= q_50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'opened 10th-quantile thresh' at 0x29fa73f8ee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th = np.average(img_gray_cp[img_gray_cp <= q_10]) - 2\n",
    "_, threshc = cv.threshold(img_gray_cp,th,255,cv.THRESH_BINARY)\n",
    "\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(4,4))\n",
    "op_threshc = cv.morphologyEx(threshc, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "viewer.add_image(threshc, name='10th-quantile thresh')\n",
    "viewer.add_image(op_threshc, name='opened 10th-quantile thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale intensity normalized over (what is assumed to be the) stained region: 115.10473198133866\n",
      "Grayscale intensity normalized over cropped region: 4.4052625058302235\n",
      "Grayscale intensity normalized over whole image: 1.5372530619303386\n"
     ]
    }
   ],
   "source": [
    "copy = op_threshc.copy()\n",
    "copy[copy == 0] = True\n",
    "copy[copy == 255] = False\n",
    "copy = copy.astype('bool')\n",
    "\n",
    "print(\"Grayscale intensity normalized over (what is assumed to be the) stained region: \" + str(np.sum(img_gray[copy])/np.sum(copy)))\n",
    "print(\"Grayscale intensity normalized over cropped region: \" + str(np.sum(img_gray[copy])/((idx_lower-idx_upper)*y)))\n",
    "print(\"Grayscale intensity normalized over whole image: \" + str(np.sum(img_gray[copy])/(x*y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imwrite(\"images/0004/grayscale.tif\", img_gray)\n",
    "cv.imwrite(\"images/0004/cropped_grayscale.tif\", img_gray_cp)\n",
    "cv.imwrite(\"images/0004/masking.tif\", threshc)\n",
    "cv.imwrite(\"images/0004/cleaned_masking.tif\", op_threshc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var  = img.astype('uint16')\n",
    "\n",
    "# [x, y, z] = var.shape \n",
    "# for i in range(x):\n",
    "#     sum_min = np.min(var[i,:,0]+var[i,:,1]+var[i,:,2])\n",
    "#     sum_max = np.max(var[i,:,0]+var[i,:,1]+var[i,:,2])\n",
    "#     diff_sum = sum_max - sum_min\n",
    "#     print(np.max(var[i,:,0])-np.min(var[i,:,0]), np.max(var[i,:,1])-np.min(var[i,:,1]), np.max(var[i,:,2])-np.min(var[i,:,2]), sum_min, sum_max, diff_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'closing' at 0x28b8c87df60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Adapative thresholding\n",
    "# thm = cv.adaptiveThreshold(img_gray_cp,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,31,2)\n",
    "# thg = cv.adaptiveThreshold(img_gray_cp,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,31,2)\n",
    "\n",
    "# kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(4,4))\n",
    "# closing = cv.morphologyEx(thm, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "# closing = cv.morphologyEx(thresh2, cv.MORPH_CLOSE, kernel)\n",
    "# num,labels,stats,centroids = cv.connectedComponentsWithStats(closing,connectivity=8)\n",
    "# for i in range(num):\n",
    "#     print(np.sum(labels==i),stats[i][4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72fca8cdcfb1fd8bc2bb90af1c9eb84e73fdb3589be0eae6bad3a7b52894a34c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
