{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arabidopsis seedlings are incubated with certain pharmaceuticals that attack the cell wall of the plants. This leads to increased production of lignin, a polymer that causes the seedlings to \"stiffen\" so that nothing can get through the cell wall anymore. For analysis, we use a specific dye that docks onto the individual lignin polymers, making them visible. And this is exactly where our interest lies. Using Fiji or ImageJ, we have to manually quantify the stained regions for every sample we analyse, sometimes several hundreds in number. Instead, we would like to have a tool that can be fed with all the images and quantifies the stained regions within seconds.\n",
    "\n",
    "<img src=\"images/root0001.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell must be excuted!\n",
    "\n",
    "First, all required packages for running the notebook are installed. Lines starting with an \"#\" are comments and will not be executed when running the respective cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import napari"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell must be excuted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(path, img, name):\n",
    "    '''\n",
    "    Method for smoothening boundaries in binarized images\n",
    "    img: image to be saved\n",
    "    name: name suffix added to original file name\n",
    "    '''\n",
    "    txt1 = path.split('.')\n",
    "    txt1 = f\"{txt1[0]}_{name}.tif\"\n",
    "    txt2 = txt1.split('\\\\')\n",
    "    txt2 = f\"{txt2[0]}_{name}\\{txt2[1]}\"\n",
    "    cv.imwrite(txt2, img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell for analysis of all images stored in images/root_images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "data = {'grayscale intensity stained region':[], 'grayscale intensity cropped region':[], 'grayscale whole image':[], 'area stained region':[], 'area cropped image':[], 'area whole image':[]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# assign directory\n",
    "directory = 'images/root_images'\n",
    "\n",
    "\n",
    "# define rgb thresholds\n",
    "low = np.array([0, 0, 0])\n",
    "high = np.array([210, 190, 217])\n",
    "\n",
    "\n",
    "# iterate over files in directory\n",
    "for filename in os.listdir(directory):\n",
    "    # path\n",
    "    f = os.path.join(directory, filename)\n",
    "\n",
    "    if f.split('.')[1] != 'tif':\n",
    "        continue\n",
    "    \n",
    "    # read image and convert to grayscale\n",
    "    og_img = cv.imread(f)\n",
    "    gray_og_img = cv.cvtColor(og_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # crop original and grayscale image\n",
    "    img = og_img[500:-(500+1),500:-(500+1),:]\n",
    "    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # compute mask\n",
    "    mask = cv.inRange(img, low, high)\n",
    "\n",
    "    # lay mask over cropped image and cropped grayscale image\n",
    "    masked_img = cv.bitwise_and(img, img, mask=mask)\n",
    "    masked_gray_img = cv.bitwise_and(gray_img, gray_img, mask=mask)\n",
    "\n",
    "    # compute area of stained region, cropped region and whole image\n",
    "    area_stained = np.sum(masked_gray_img > 0)\n",
    "    area_cropped = img.shape[0]*img.shape[1]\n",
    "    area_whole = og_img.shape[0]*og_img.shape[1]\n",
    "\n",
    "    # compute grayscale intensities\n",
    "    intensity_stained = np.sum(masked_gray_img) / area_stained\n",
    "    intensity_cropped = np.sum(masked_gray_img) / area_cropped\n",
    "    intensity_whole = np.sum(masked_gray_img) / area_whole\n",
    "\n",
    "    # add new data to dataframe\n",
    "    new_row = np.array([intensity_stained, intensity_cropped, intensity_whole, area_stained, area_cropped, area_whole])\n",
    "    df.loc[len(df)] = new_row\n",
    "    \n",
    "    # save masked, cropped image\n",
    "    save_img(f, masked_img, 'msk')\n",
    "\n",
    "\n",
    "# create excel table from dataframe\n",
    "df.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72fca8cdcfb1fd8bc2bb90af1c9eb84e73fdb3589be0eae6bad3a7b52894a34c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
